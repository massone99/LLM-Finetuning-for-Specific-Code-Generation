[
  {
    "conversations": [
      {
        "from": "human",
        "value": "Use Akka Persistence Typed to build an advanced aggregator that collects partial tasks from multiple users, snapshots state, and recovers on startup."
      },
      {
        "from": "assistant",
        "value": "// AdvancedAggregator.scala\n\n/*\n  This example demonstrates a highly complex scenario using Akka Persistence Typed.\n  The aggregator collects partial tasks from multiple users, persists them as events,\n  periodically snapshots, and recovers its state after a restart.\n\n  Key points:\n  1. We define a sealed trait Command to represent user commands.\n  2. We define events that capture updates to aggregator state.\n  3. We handle these events in an event handler, building up aggregator data.\n  4. We use a snapshot strategy to periodically store snapshots.\n  5. On recovery, the aggregator replays events or a snapshot + events.\n  6. The aggregator can process partial tasks from many users, combining them.\n  7. On \"Print\" command, it displays the aggregated info.\n  8. On \"CompleteTask\" command, it might produce a final event to finalize.\n*/\n\nimport akka.actor.typed.scaladsl.{Behaviors, EventSourcedBehavior}\nimport akka.actor.typed.{ActorSystem, Behavior}\nimport akka.persistence.typed.{PersistenceId, SnapshotAdapter}\nimport akka.persistence.typed.scaladsl.{RetentionCriteria, Effect}\n\nobject AdvancedAggregator {\n\n  // Commands represent all possible messages the aggregator can receive\n  sealed trait Command\n  case class AddPartial(userId: String, partial: String) extends Command\n  case object Print extends Command\n  case class CompleteTask(userId: String) extends Command\n\n  // Events represent all state changes to be persisted\n  sealed trait Event\n  case class PartialAdded(userId: String, partial: String) extends Event\n  case class TaskCompleted(userId: String) extends Event\n\n  // State holds aggregated partial tasks.\n  // For each user, we store a list of partial strings.\n  final case class AggregatorState(tasks: Map[String, List[String]]) {\n    def addPartial(userId: String, partial: String): AggregatorState = {\n      val existing = tasks.getOrElse(userId, Nil)\n      copy(tasks = tasks.updated(userId, existing :+ partial))\n    }\n    def completeTask(userId: String): AggregatorState = {\n      // For demo, we might just clear that user's partials.\n      copy(tasks = tasks - userId)\n    }\n  }\n\n  // We define the main behavior as an EventSourcedBehavior\n  // that deals with commands, persists events, and updates state.\n  def apply(entityId: String): Behavior[Command] = EventSourcedBehavior[\n    Command,\n    Event,\n    AggregatorState\n  ](\n    persistenceId = PersistenceId.ofUniqueId(entityId),\n    // Start with empty aggregator state if no snapshot or events exist\n    emptyState = AggregatorState(Map.empty),\n\n    // Command handler transforms commands into events (or performs side-effects)\n    commandHandler = (state, command) => command match {\n      case AddPartial(userId, partial) =>\n        // We persist a PartialAdded event to represent this update\n        Effect.persist(PartialAdded(userId, partial))\n      case Print =>\n        // Just a side-effect: printing current aggregator info\n        println(\"Current aggregator state:\")\n        state.tasks.foreach {\n          case (u, partials) =>\n            println(s\"User: $u -> partials: ${partials.mkString(\", \")}\")\n        }\n        // No event needed, so we do an Effect.none\n        Effect.none\n      case CompleteTask(userId) =>\n        // We'll create a TaskCompleted event\n        Effect.persist(TaskCompleted(userId))\n    },\n\n    // Event handler updates the in-memory AggregatorState\n    eventHandler = (state, event) => event match {\n      case PartialAdded(u, p) =>\n        state.addPartial(u, p)\n      case TaskCompleted(u) =>\n        state.completeTask(u)\n    }\n  ).withRetention(\n    // Snapshot after every 5 events, keep last 2 snapshots, for demonstration\n    RetentionCriteria.snapshotEvery(numberOfEvents = 5, keepNSnapshots = 2)\n  )\n}\n\nobject AdvancedAggregatorApp extends App {\n  // Create the typed ActorSystem\n  val system = ActorSystem(AdvancedAggregator(\"aggregator-1\"), \"AdvancedAggregatorSystem\")\n\n  // Demo usage:\n  system ! AdvancedAggregator.AddPartial(\"alice\", \"part1\")\n  system ! AdvancedAggregator.AddPartial(\"alice\", \"part2\")\n  system ! AdvancedAggregator.AddPartial(\"bob\", \"partialB1\")\n\n  system ! AdvancedAggregator.Print\n  system ! AdvancedAggregator.CompleteTask(\"alice\")\n  system ! AdvancedAggregator.Print\n\n  // Wait for a moment, then shutdown\n  Thread.sleep(3000)\n  system.terminate()\n}\n"
      }
    ]
  },
  {
    "conversations": [
      {
        "from": "human",
        "value": "Use Akka Typed to build a deeply nested hierarchical structure of actors that pass messages up and down the hierarchy."
      },
      {
        "from": "assistant",
        "value": "// NestedHierarchyExample.scala\n\n/*\n  This example shows a complex hierarchical structure in Akka Typed:\n  - A top-level Manager actor spawns multiple Coordinators.\n  - Each Coordinator spawns multiple Workers.\n  - Messages can flow from Manager -> Coordinator -> Worker.\n  - Workers can also send updates back up the chain.\n\n  We'll define a set of typed messages for each layer.\n*/\n\nimport akka.actor.typed.scaladsl.Behaviors\nimport akka.actor.typed.{ActorRef, ActorSystem, Behavior}\n\n// Worker messages\nobject Worker {\n  sealed trait Command\n  case class DoWork(task: String) extends Command\n  case class ReportBack(status: String, replyTo: ActorRef[Coordinator.WorkerStatus]) extends Command\n\n  // Worker behavior simply logs tasks and can report back to the coordinator\n  def apply(workerId: Int): Behavior[Command] = Behaviors.receive { (ctx, msg) =>\n    msg match {\n      case DoWork(task) =>\n        ctx.log.info(s\"Worker-$workerId processing task: $task\")\n        Behaviors.same\n      case ReportBack(status, replyTo) =>\n        ctx.log.info(s\"Worker-$workerId reporting status: $status\")\n        replyTo ! Coordinator.WorkerStatus(workerId, status)\n        Behaviors.same\n    }\n  }\n}\n\n// Coordinator messages\nobject Coordinator {\n  sealed trait Command\n  // Command from manager to schedule work\n  case class ScheduleWork(task: String) extends Command\n  // Command from manager to request statuses\n  case object RequestStatuses extends Command\n  // Coordinator spawns multiple workers, so it needs a child creation message\n  case class CreateWorkers(num: Int) extends Command\n  // WorkerStatus is a message the worker sends back (via the worker's ReportBack)\n  case class WorkerStatus(workerId: Int, status: String) extends Command\n\n  def apply(coordinatorId: Int): Behavior[Command] = Behaviors.setup { ctx =>\n    var workers = List.empty[ActorRef[Worker.Command]]\n\n    Behaviors.receiveMessage {\n      case CreateWorkers(num) =>\n        // Spawn the desired number of workers\n        for (i <- 1 to num) {\n          val ref = ctx.spawn(Worker(i), s\"worker-$coordinatorId-$i\")\n          workers ::= ref\n        }\n        ctx.log.info(s\"Coordinator-$coordinatorId: Created $num workers.\")\n        Behaviors.same\n\n      case ScheduleWork(task) =>\n        // Just distribute the work among all workers (in a naive approach)\n        workers.foreach { w =>\n          w ! Worker.DoWork(task)\n        }\n        Behaviors.same\n\n      case RequestStatuses =>\n        // Ask each worker to report back\n        workers.foreach { w =>\n          w ! Worker.ReportBack(s\"TaskProgress?\", ctx.self)\n        }\n        Behaviors.same\n\n      case WorkerStatus(workerId, status) =>\n        ctx.log.info(s\"Coordinator-$coordinatorId received status from worker-$workerId: $status\")\n        Behaviors.same\n    }\n  }\n}\n\n// Manager messages\nobject Manager {\n  sealed trait Command\n  case class CreateCoordinator(id: Int, workerCount: Int) extends Command\n  case class BroadcastWork(task: String) extends Command\n  case object CollectAllStatuses extends Command\n\n  def apply(): Behavior[Command] = Behaviors.setup { ctx =>\n    var coordinators = Map.empty[Int, ActorRef[Coordinator.Command]]\n\n    Behaviors.receiveMessage {\n      case CreateCoordinator(id, workerCount) =>\n        val ref = ctx.spawn(Coordinator(id), s\"coord-$id\")\n        ref ! Coordinator.CreateWorkers(workerCount)\n        coordinators = coordinators.updated(id, ref)\n        ctx.log.info(s\"Manager: Created coordinator $id with $workerCount workers.\")\n        Behaviors.same\n\n      case BroadcastWork(task) =>\n        // Send the given task to all known coordinators\n        coordinators.values.foreach { coord =>\n          coord ! Coordinator.ScheduleWork(task)\n        }\n        Behaviors.same\n\n      case CollectAllStatuses =>\n        // Request statuses from each coordinator\n        coordinators.values.foreach { coord =>\n          coord ! Coordinator.RequestStatuses\n        }\n        Behaviors.same\n    }\n  }\n}\n\nobject NestedHierarchyExampleApp extends App {\n  // Create the top-level Manager actor system\n  val system = ActorSystem(Manager(), \"ManagerSystem\")\n\n  // Create two coordinators, each with a certain number of workers\n  system ! Manager.CreateCoordinator(id = 1, workerCount = 3)\n  system ! Manager.CreateCoordinator(id = 2, workerCount = 2)\n\n  // Let them initialize\n  Thread.sleep(1000)\n\n  // Broadcast work to all coordinators (and thus to all workers)\n  system ! Manager.BroadcastWork(\"DataProcessingTask\")\n\n  // Request statuses from all coordinators\n  system ! Manager.CollectAllStatuses\n\n  Thread.sleep(3000)\n  system.terminate()\n}\n"
      }
    ]
  },
  {
    "conversations": [
      {
        "from": "human",
        "value": "Build a typed actor that dynamically spawns child persistent actors on demand and aggregates results from them."
      },
      {
        "from": "assistant",
        "value": "// DynamicPersistentChildrenExample.scala\n\n/*\n  In this advanced scenario:\n  - The ParentActor is a typed actor that spawns child persistent actors on demand.\n  - Each child is an EventSourcedBehavior-based actor.\n  - The parent can route commands to a child, and then gather results.\n  - This can be used to scale out persistent data storage for multiple entities.\n*/\n\nimport akka.actor.typed.scaladsl.{Behaviors, ActorContext}\nimport akka.actor.typed.{Behavior, ActorSystem, ActorRef}\nimport akka.persistence.typed.{PersistenceId}\nimport akka.persistence.typed.scaladsl.{EventSourcedBehavior, Effect}\nimport scala.util.Random\n\n// Child persistent actor code\nobject PersistentChild {\n  // Commands\n  sealed trait Command\n  case class Add(value: Int) extends Command\n  case object Show extends Command\n  case class GetState(replyTo: ActorRef[Int]) extends Command\n\n  // Events\n  sealed trait Event\n  case class Added(value: Int) extends Event\n\n  // State\n  case class State(sum: Int)\n\n  def apply(childId: String): Behavior[Command] = EventSourcedBehavior[\n    Command,\n    Event,\n    State\n  ](\n    persistenceId = PersistenceId.ofUniqueId(childId),\n    emptyState = State(0),\n    commandHandler = (state, command) => command match {\n      case Add(v) =>\n        Effect.persist(Added(v))\n      case Show =>\n        println(s\"Child-$childId => current sum is ${state.sum}\")\n        Effect.none\n      case GetState(replyTo) =>\n        replyTo ! state.sum\n        Effect.none\n    },\n    eventHandler = (state, event) => event match {\n      case Added(v) => state.copy(sum = state.sum + v)\n    }\n  )\n}\n\n// Parent typed actor that spawns the child persistent actors\nobject ParentManager {\n  // Manager commands\n  sealed trait ManagerCommand\n  case class SpawnChild(id: String) extends ManagerCommand\n  case class ForwardToChild(childId: String, cmd: PersistentChild.Command) extends ManagerCommand\n  case object GatherAllStates extends ManagerCommand\n  case class ChildStateResponse(childId: String, sum: Int) extends ManagerCommand\n\n  def apply(): Behavior[ManagerCommand] = Behaviors.setup { context =>\n    var children = Map.empty[String, ActorRef[PersistentChild.Command]]\n\n    Behaviors.receiveMessage {\n      case SpawnChild(id) =>\n        // Dynamically spawn a persistent child\n        val ref = context.spawn(PersistentChild(id), s\"persistentChild-$id\")\n        children = children.updated(id, ref)\n        context.log.info(s\"Spawned persistent child with id: $id\")\n        Behaviors.same\n\n      case ForwardToChild(childId, cmd) =>\n        children.get(childId) match {\n          case Some(childRef) =>\n            childRef ! cmd\n          case None =>\n            context.log.warn(s\"Child $childId does not exist.\")\n        }\n        Behaviors.same\n\n      case GatherAllStates =>\n        // We'll ask each child for its current sum\n        children.foreach { case (id, ref) =>\n          // We'll adapt the response: first we need a temporary adapter or\n          // we do a trick: define a message in child that returns to parent.\n          // We'll do that with an ask pattern or message adapter.\n\n          // For brevity, let's do a direct approach by spawning a short-living behavior.\n\n          // Instead, let's define a quick approach:\n          // We'll create a context.messageAdapter to handle ChildStateResponse.\n          val adapter = context.spawnAnonymous(\n            Behaviors.receiveMessage[Int] { sum =>\n              context.self ! ChildStateResponse(id, sum)\n              Behaviors.stopped\n            }\n          )\n          ref ! PersistentChild.GetState(adapter)\n        }\n        Behaviors.same\n\n      case ChildStateResponse(childId, sum) =>\n        context.log.info(s\"Child $childId has sum = $sum\")\n        Behaviors.same\n    }\n  }\n}\n\nobject DynamicPersistentChildrenExampleApp extends App {\n  val system = ActorSystem(ParentManager(), \"DynamicPersistentChildrenSystem\")\n\n  // Spawn two persistent children\n  system ! ParentManager.SpawnChild(\"childA\")\n  system ! ParentManager.SpawnChild(\"childB\")\n\n  Thread.sleep(1000)\n\n  // Forward some commands\n  system ! ParentManager.ForwardToChild(\"childA\", PersistentChild.Add(10))\n  system ! ParentManager.ForwardToChild(\"childA\", PersistentChild.Show)\n  system ! ParentManager.ForwardToChild(\"childB\", PersistentChild.Add(5))\n  system ! ParentManager.ForwardToChild(\"childB\", PersistentChild.Add(15))\n\n  Thread.sleep(1000)\n\n  system ! ParentManager.GatherAllStates\n\n  Thread.sleep(3000)\n  system.terminate()\n}\n"
      }
    ]
  },
  {
    "conversations": [
      {
        "from": "human",
        "value": "Use Akka Typed Streams to define a high-complexity stream that merges multiple dynamic sub-streams and uses advanced operators."
      },
      {
        "from": "assistant",
        "value": "// ComplexTypedStreamExample.scala\n\n/*\n  This example shows a relatively high-complexity usage of Akka Streams with typed contexts.\n\n  Steps:\n  1. We create multiple sub-sources of data that we combine with MergeHub.\n  2. We feed them into a processing Flow that applies advanced operators like buffer, mapAsync.\n  3. We route outputs to a BroadcastHub so additional dynamic consumers can attach.\n  4. We produce a final sink that logs results.\n  5. This architecture allows dynamic producers and consumers.\n*/\n\nimport akka.actor.ActorSystem\nimport akka.stream.ActorMaterializer\nimport akka.stream.scaladsl._\nimport scala.concurrent.ExecutionContext\nimport scala.concurrent.Future\nimport scala.util.Random\n\nobject ComplexTypedStreamExample extends App {\n  implicit val system: ActorSystem = ActorSystem(\"ComplexTypedStreamSystem\")\n  implicit val mat: ActorMaterializer = ActorMaterializer()(system)\n  implicit val ec: ExecutionContext = system.dispatcher\n\n  // 1. MergeHub allows multiple producers to connect.\n  val (mergeHubSink, mergeHubSource) = MergeHub.source[String](perProducerBufferSize = 16).preMaterialize()\n\n  // 2. Our processing flow: buffer, mapAsync, filter, etc.\n  val processingFlow = Flow[String]\n    .buffer(32, OverflowStrategy.backpressure)\n    .mapAsync(parallelism = 4) { elem =>\n      // Simulate some asynchronous processing\n      Future {\n        if (Random.nextDouble() < 0.2) {\n          throw new RuntimeException(\"Random failure!\")\n        }\n        elem.toUpperCase\n      }\n    }\n    .recover {\n      case ex: Throwable => s\"[ERROR: ${ex.getMessage}]\"\n    }\n    .filterNot(_.startsWith(\"[ERROR\"))\n    .map(elem => s\"Processed => $elem\")\n\n  // 3. BroadcastHub for dynamic consumers\n  val (broadcastHubSource, broadcastHubSink) = processingFlow\n    .runWith(BroadcastHub.sink[String], mergeHubSource)\n\n  // Actually, we have to connect the source from MergeHub to the sink.\n  // Letâ€™s do that properly:\n  // We run the MergeHub source through the processingFlow, and then into a BroadcastHub.\n\n  val finalRunnable = mergeHubSource\n    .via(processingFlow)\n    .to(broadcastHubSink)\n\n  finalRunnable.run()\n\n  // 4. Now broadcastHubSource is a Source we can attach multiple dynamic sinks to\n\n  val finalSink = Sink.foreach[String](msg => println(s\"Final sink consumed: $msg\"))\n\n  // attach the broadcast source to final sink\n  broadcastHubSource.runWith(finalSink)\n\n  // 5. We'll create a couple ephemeral sources feeding data into mergeHubSink.\n\n  Source(List(\"alpha\", \"bravo\", \"charlie\"))\n    .to(Sink.fromSubscriber(mergeHubSink)).run()\n\n  Source(List(\"delta\", \"echo\", \"foxtrot\"))\n    .to(Sink.fromSubscriber(mergeHubSink)).run()\n\n  // Wait a bit, then shut down\n  Thread.sleep(3000)\n  system.terminate()\n}\n"
      }
    ]
  },
  {
    "conversations": [
      {
        "from": "human",
        "value": "Demonstrate an ultra-complex typed actor scenario: multiple FSM states, advanced context interactions, and cluster-based scaling."
      },
      {
        "from": "assistant",
        "value": "// UltraComplexFSMClusterExample.scala\n\n/*\n  This scenario is designed to show an extremely sophisticated combination:\n\n  1. A typed FSM that has multiple states: Idle, Working, WaitingForCluster.\n  2. It interacts with a cluster, waiting for a minimum number of members.\n  3. Once the cluster is large enough, it transitions to a Working state.\n  4. In the Working state, it can accept tasks, possibly store them in memory.\n  5. Then it can move to an Idle state if a pause message is received.\n  6. We demonstrate advanced usage of timers, cluster membership checks, and typed FSM illusions via Behaviors.\n\n  Because typed FSM is not built-in, we simulate an FSM by manually handling states and transitions with become.\n*/\n\nimport akka.actor.typed.scaladsl.{Behaviors, ActorContext, TimerScheduler}\nimport akka.actor.typed.{ActorRef, ActorSystem, Behavior}\nimport akka.cluster.typed.{Cluster, Subscribe, SelfUp, MemberUp, MembershipEvent}\nimport scala.concurrent.duration._\n\nobject UltraComplexFSM {\n  // Sealed trait for commands\n  sealed trait Command\n\n  // Commands for cluster-based transitions\n  case object CheckClusterSize extends Command\n  case object StartWork extends Command\n  case object PauseWork extends Command\n  case class AddTask(task: String) extends Command\n  case class PrintTasks(replyTo: ActorRef[String]) extends Command\n  private case class MemberUpEvent(evt: MemberUp) extends Command\n\n  // We'll define a config param for min cluster size\n  // so we only start working if cluster members >= that.\n  final case class Config(minClusterSize: Int)\n\n  def apply(config: Config): Behavior[Command] = Behaviors.setup { ctx =>\n    // We'll subscribe to cluster membership events\n    val cluster = Cluster(ctx.system)\n    cluster.subscriptions ! Subscribe(ctx.self, classOf[MemberUp])\n\n    // We start in the \"WaitingForCluster\" state\n    waitingForCluster(config, membersCount = cluster.state.members.size, tasks = List.empty)\n  }\n\n  // waitingForCluster: we do not accept tasks or start real work until we have enough members\n  private def waitingForCluster(\n    config: Config,\n    membersCount: Int,\n    tasks: List[String]\n  ): Behavior[Command] = Behaviors.receive { (ctx, msg) =>\n    msg match {\n      case MemberUpEvent(MemberUp(_)) =>\n        val newCount = membersCount + 1\n        ctx.log.info(s\"A new member joined! Cluster size = $newCount\")\n        if (newCount >= config.minClusterSize) {\n          ctx.log.info(\"Minimum cluster size satisfied. Transitioning to Idle.\")\n          idle(config, newCount, tasks)\n        } else {\n          waitingForCluster(config, newCount, tasks)\n        }\n\n      case AddTask(task) =>\n        // We can store tasks even though not operational, or ignore them.\n        val updated = tasks :+ task\n        ctx.log.info(s\"Storing task while waiting for cluster: $task\")\n        waitingForCluster(config, membersCount, updated)\n\n      case PrintTasks(replyTo) =>\n        replyTo ! s\"Tasks while waiting: ${tasks.mkString(\", \")}, cluster size = $membersCount\"\n        Behaviors.same\n\n      case _ => Behaviors.same\n    }\n  }\n\n  // Once we have enough cluster members, we move to an Idle state.\n  private def idle(\n    config: Config,\n    membersCount: Int,\n    tasks: List[String]\n  ): Behavior[Command] = Behaviors.receive { (ctx, msg) =>\n    msg match {\n      case StartWork =>\n        ctx.log.info(\"Transitioning from Idle to Working.\")\n        working(config, membersCount, tasks)\n\n      case AddTask(task) =>\n        // We can accumulate tasks while idle.\n        val updated = tasks :+ task\n        ctx.log.info(s\"Task queued while idle: $task\")\n        idle(config, membersCount, updated)\n\n      case PrintTasks(replyTo) =>\n        replyTo ! s\"Idle tasks: ${tasks.mkString(\", \")}, cluster size = $membersCount\"\n        Behaviors.same\n\n      case MemberUpEvent(MemberUp(_)) =>\n        // cluster grew, update count\n        val newCount = membersCount + 1\n        ctx.log.info(s\"New member joined while idle, cluster size = $newCount\")\n        idle(config, newCount, tasks)\n\n      case _ => Behaviors.same\n    }\n  }\n\n  // In working state, we can accept tasks and process them, or pause to return to idle.\n  private def working(\n    config: Config,\n    membersCount: Int,\n    tasks: List[String]\n  ): Behavior[Command] = Behaviors.receive { (ctx, msg) =>\n    msg match {\n      case AddTask(task) =>\n        // Let's consider the tasks are immediately processed.\n        ctx.log.info(s\"Working on task: $task\")\n        working(config, membersCount, tasks :+ task)\n\n      case PrintTasks(replyTo) =>\n        replyTo ! s\"Working tasks so far: ${tasks.mkString(\", \")}, cluster size = $membersCount\"\n        Behaviors.same\n\n      case PauseWork =>\n        ctx.log.info(\"Pausing work, transitioning to Idle.\")\n        idle(config, membersCount, tasks)\n\n      case MemberUpEvent(MemberUp(_)) =>\n        // cluster grew in the meantime\n        val newCount = membersCount + 1\n        ctx.log.info(s\"Cluster gained a new member, total = $newCount while working.\")\n        working(config, newCount, tasks)\n\n      case _ => Behaviors.same\n    }\n  }\n}\n\nobject UltraComplexFSMClusterApp extends App {\n  import UltraComplexFSM._\n\n  // We'll define a config requiring a cluster of size 2 before we start.\n  val system = ActorSystem(UltraComplexFSM(Config(minClusterSize = 2)), \"UltraFSMClusterSystem\")\n\n  // For local testing without an actual cluster, we can forcibly inject a MemberUpEvent for demonstration:\n  system ! MemberUpEvent(null) // Pretend we have 1 member\n\n  // Try adding tasks, see them stored while not enough members.\n  system ! AddTask(\"Task1\")\n  system ! AddTask(\"Task2\")\n\n  // Force a second member join event\n  system ! MemberUpEvent(null)\n\n  // Now we should transition to Idle, let's add tasks in Idle\n  system ! AddTask(\"IdleTask1\")\n\n  // Move to working\n  system ! StartWork\n  system ! AddTask(\"WorkTask1\")\n\n  // Pause\n  Thread.sleep(1000)\n  system ! PauseWork\n\n  Thread.sleep(2000)\n  system.terminate()\n}\n"
      }
    ]
  }
]
