
== 
Evaluation Results (before_finetuning):


=== 
Average BLEU Score: 0.0980

 
Detailed results saved to: ./res/data/results/evaluation_results_before_finetuning_20241220.json

 Running examples: 0/17

== 
Evaluation Results (after_finetuning_trainsize45):


=== 
Average BLEU Score: 0.3840

 
Detailed results saved to: ./res/data/results/evaluation_results_after_finetuning_trainsize45_20241220.json

 Running examples: 5/17
