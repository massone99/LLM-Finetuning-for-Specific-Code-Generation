llm/*
llama_finetune/outputs/
# Ignore the dot files
.*
# Ignore the code generated by the fine-tuned model
llama_finetune/data/generated_code/*

*/__pycache__/*